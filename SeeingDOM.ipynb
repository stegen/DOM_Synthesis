{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nUmk4xLQZMfs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "i6Ney8CwZwYf"
   },
   "outputs": [],
   "source": [
    "link_to_drive = \"C:/Users/erika/OneDrive/Desktop/\" \n",
    "file_path = \"Merged_Processed_Data - 10-19-23.csv\"\n",
    "files_toclean = pd.read_csv(link_to_drive + file_path)\n",
    "files_toclean.set_index('Calibrated m/z', inplace=True)\n",
    "# Sort/reorder by index\n",
    "files_toclean = files_toclean.sort_index()\n",
    "abspres = (files_toclean != 0).astype(int)\n",
    "out_file = 'C:/Users/erika/OneDrive/Desktop/Merged_Processed_Data - 10-19-23_ECF.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "H03hrR79k6QZ",
    "outputId": "62ed0ed6-4766-4b8c-cb08-eceb00d63262"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nselect_columns_containing: Returns columns containing the specified substring.\\nremove_columns_and_report: Removes columns based on the \\'country.year\\' pattern, but retains those with the \\'dil\\' keyword. Also, provides a report on how many columns contain \"dil\" and lists the columns that were removed.\\nremove_pattern1: Removes the pattern \\\\d{5}\\\\.corems from a string.\\nremove_after_dil_dill: Removes everything after \"dil\" or \"dill\" in column names.\\nremove_manyfiles_prefix: Removes the \"ManyFiles_\" prefix from column names.\\nremove_strings_from_segments: Removes segments from column names that start with specific keywords.\\nadjust_column_names: Modifies column names to replace \\'.\\' with \\'_\\' and ensures an underscore after the first string segment.\\ntrim_columns_after_first_number: Trims the column names after the first number.\\nreplace_sweden_with_swed: Replaces the occurrence of \"Sweden\" with \"Swed\" in column names.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "select_columns_containing: Returns columns containing the specified substring.\n",
    "remove_columns_and_report: Removes columns based on the 'country.year' pattern, but retains those with the 'dil' keyword. Also, provides a report on how many columns contain \"dil\" and lists the columns that were removed.\n",
    "remove_pattern1: Removes the pattern \\d{5}\\.corems from a string.\n",
    "remove_after_dil_dill: Removes everything after \"dil\" or \"dill\" in column names.\n",
    "remove_manyfiles_prefix: Removes the \"ManyFiles_\" prefix from column names.\n",
    "remove_strings_from_segments: Removes segments from column names that start with specific keywords.\n",
    "adjust_column_names: Modifies column names to replace '.' with '_' and ensures an underscore after the first string segment.\n",
    "trim_columns_after_first_number: Trims the column names after the first number.\n",
    "replace_sweden_with_swed: Replaces the occurrence of \"Sweden\" with \"Swed\" in column names.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gtAmeT_w5BgD"
   },
   "outputs": [],
   "source": [
    "def select_columns_containing(df, substring):\n",
    "    \"\"\"\n",
    "    Select columns that contain the specified substring.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame to be filtered.\n",
    "    - substring: The string to look for in column names.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame containing only the columns with the specified substring in their name.\n",
    "    \"\"\"\n",
    "    return df[[col for col in df.columns if substring in col]]\n",
    "\n",
    "def remove_columns_and_report(df):\n",
    "    \"\"\"\n",
    "    Remove columns based on the 'country.year' pattern, but keep those with 'dil' keyword.\n",
    "    Produce a report on how many columns contain \"dil\" and list the columns that were removed.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame to be filtered.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame excluding the undesired columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Use regular expressions to identify the country and year pattern\n",
    "    pattern = re.compile(r'([A-Za-z]+)\\.(\\d{2})')\n",
    "\n",
    "    # Find the country.year components and store them\n",
    "    matches = [pattern.search(col) for col in df.columns]\n",
    "    display(matches)\n",
    "    country_year_components = [match.group(0) for match in matches if match]\n",
    "\n",
    "    # Identify the unique country.year components\n",
    "    unique_components = set(country_year_components)\n",
    "\n",
    "    # Filter columns\n",
    "    columns_to_remove = []\n",
    "\n",
    "    for component in unique_components:\n",
    "        component_cols = [col for col in df.columns if component in col]\n",
    "        # Check if any of the columns for this component contains 'dil'\n",
    "        has_dil = any(['dil' in col for col in component_cols])\n",
    "        if has_dil:\n",
    "            columns_to_remove.extend([col for col in component_cols if 'dil' not in col])\n",
    "\n",
    "    # Remove the identified columns\n",
    "    df_cleaned = df.drop(columns=columns_to_remove)\n",
    "\n",
    "    # Report\n",
    "    dil_columns = [col for col in df.columns if 'dil' in col]\n",
    "    print(f\"Total columns containing 'dil': {len(dil_columns)}\")\n",
    "    print(f\"Columns removed: {', '.join(columns_to_remove)}\")\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "def remove_pattern1(column_name):\n",
    "    return re.sub(r'\\d{5}\\.corems', '', column_name)\n",
    "\n",
    "def prefix_dil_if_present(df):\n",
    "    \"\"\"\n",
    "    Add \"dil_\" to the beginning of column names if they contain \"dil\".\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame to modify.\n",
    "\n",
    "    Returns:\n",
    "    - Modified DataFrame with updated column names.\n",
    "    \"\"\"\n",
    "\n",
    "    def prefix_dil(col):\n",
    "        if 'dil' in col:\n",
    "            return 'retain_' + col\n",
    "        else:\n",
    "            return col\n",
    "\n",
    "    df.columns = [prefix_dil(col) for col in df.columns]\n",
    "    return df\n",
    "\n",
    "def remove_after_dil_dill(df):\n",
    "    \"\"\"\n",
    "    Remove strings that come after \"dil\" or \"dill\" in column names of a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame to modify.\n",
    "\n",
    "    Returns:\n",
    "    - Modified DataFrame with updated column names.\n",
    "    \"\"\"\n",
    "\n",
    "    def clean_column_name(col):\n",
    "        if 'dil' in col:\n",
    "            return col.split('dil', 1)[0]\n",
    "        else:\n",
    "            return col\n",
    "\n",
    "    df.columns = [clean_column_name(col) for col in df.columns]\n",
    "    return df\n",
    "\n",
    "def remove_manyfiles_prefix(df):\n",
    "    \"\"\"\n",
    "    Remove the \"ManyFiles_\" prefix from column names of a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame to modify.\n",
    "\n",
    "    Returns:\n",
    "    - Modified DataFrame with updated column names.\n",
    "    \"\"\"\n",
    "\n",
    "    df.columns = [col.replace('ManyFiles_', '') for col in df.columns]\n",
    "    return df\n",
    "\n",
    "def remove_strings_from_segments(df):\n",
    "    \"\"\"\n",
    "    Remove segments of column names that start with specific strings.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame to modify.\n",
    "\n",
    "    Returns:\n",
    "    - Modified DataFrame with updated column names.\n",
    "    \"\"\"\n",
    "\n",
    "    unwanted_starts = [\"MGC\", \"FTMS\", \"Lakes\", \"FJ\"]\n",
    "\n",
    "    def replace_unwanted_segments(col):\n",
    "        segments = col.split('_')\n",
    "        filtered_segments = [segment for segment in segments if not any(segment.startswith(unwanted) for unwanted in unwanted_starts)]\n",
    "        return '_'.join(filtered_segments)\n",
    "\n",
    "    df.columns = [replace_unwanted_segments(col) for col in df.columns]\n",
    "    return df\n",
    "\n",
    "\n",
    "def adjust_column_names(df):\n",
    "    \"\"\"\n",
    "    Adjust the column names based on the criteria:\n",
    "    1. Replace a '.' with '_'.\n",
    "    2. Insert an underscore after the first string segment if it's not already present.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame to modify.\n",
    "\n",
    "    Returns:\n",
    "    - Modified DataFrame with updated column names.\n",
    "    \"\"\"\n",
    "\n",
    "    def process_colname(col):\n",
    "        col = col.replace('.', '_')  # Replace '.' with '_'\n",
    "\n",
    "        # Add underscore after the first string if it's not already present\n",
    "        match = re.match(r'^([a-zA-Z]+)(?![a-zA-Z_])', col)\n",
    "        if match:\n",
    "            prefix = match.group(1)\n",
    "            col = col.replace(prefix, prefix + \"_\", 1)  # replace only the first occurrence\n",
    "\n",
    "        return col\n",
    "\n",
    "    df.columns = [process_colname(col) for col in df.columns]\n",
    "    return df\n",
    "\n",
    "def trim_columns_after_first_number(df):\n",
    "    \"\"\"\n",
    "    Trims the column names of a DataFrame after the first number.\n",
    "\n",
    "    Parameters:\n",
    "    - df: Input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with modified column names.\n",
    "    \"\"\"\n",
    "    def trim_after_first_number(col_name):\n",
    "        match = re.match(r'^([a-zA-Z_]+?)(\\d+)', col_name)\n",
    "        if match:\n",
    "            return match.group(1) + match.group(2)\n",
    "        else:\n",
    "            return col_name\n",
    "\n",
    "    df.columns = [trim_after_first_number(col) for col in df.columns]\n",
    "    return df\n",
    "\n",
    "def replace_sweden_with_swed(df):\n",
    "    \"\"\"\n",
    "    Replaces the occurrence of \"Sweden\" with \"Swed\" in column names.\n",
    "\n",
    "    Parameters:\n",
    "    - df: Input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with modified column names.\n",
    "    \"\"\"\n",
    "    df.columns = [col.replace('Sweden', 'Swed') for col in df.columns]\n",
    "    return df\n",
    "\n",
    "def drop_matching_columns_without_prefix(df, prefix=\"retain_\"):\n",
    "    \"\"\"\n",
    "    Drop columns that have a matching counterpart with the specified prefix.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame to be filtered.\n",
    "    - prefix: The prefix to look for in column names.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame without the columns that have a matching counterpart with the prefix.\n",
    "    \"\"\"\n",
    "\n",
    "    # Identify columns with the prefix\n",
    "    prefixed_cols = [col for col in df.columns if col.startswith(prefix)]\n",
    "\n",
    "    # Identify the matching columns without the prefix\n",
    "    matching_cols_to_drop = [col.replace(prefix, \"\") for col in prefixed_cols if col.replace(prefix, \"\") in df.columns]\n",
    "\n",
    "    return df.drop(columns=matching_cols_to_drop)\n",
    "\n",
    "\n",
    "def remove_retain_prefix(df):\n",
    "    \"\"\"\n",
    "    Remove the \"retain_\" prefix from column names of a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame to modify.\n",
    "\n",
    "    Returns:\n",
    "    - Modified DataFrame with updated column names.\n",
    "    \"\"\"\n",
    "\n",
    "    df.columns = [col.replace('retain_', '') for col in df.columns]\n",
    "    return df\n",
    "\n",
    "def remove_columns_with_substring(df, substring):\n",
    "    \"\"\"Remove all columns containing a specific substring.\"\"\"\n",
    "    cols_to_remove = [col for col in df.columns if substring in col]\n",
    "    return df.drop(columns=cols_to_remove)\n",
    "\n",
    "\n",
    "def merge_and_export(df_original, df_cleaned, filename):\n",
    "    \"\"\"Merge two DataFrames and export to CSV.\"\"\"\n",
    "    # Remove 'ManyFiles' columns\n",
    "    df_original = remove_columns_with_substring(df_original, 'ManyFiles')\n",
    "    # Merge with cleaned columns\n",
    "    df_combined = pd.concat([df_original, df_cleaned], axis=1)\n",
    "    # Export to CSV\n",
    "    df_combined.to_csv(filename, index=False)\n",
    "    return df_combined\n",
    "\n",
    "def clean_the_names(df):\n",
    "    filtered_df = select_columns_containing(df, 'ManyFiles') #290 samples only with J's sample codes\n",
    "    filtered_df.columns = [remove_pattern1(col) for col in filtered_df.columns]\n",
    "    dil = prefix_dil_if_present(filtered_df)\n",
    "    no_dil = remove_after_dil_dill(dil)\n",
    "    nomanyfiles = remove_manyfiles_prefix(no_dil)\n",
    "    no_MGC = remove_strings_from_segments(nomanyfiles)\n",
    "    no_MGC_segment = adjust_column_names(no_MGC)\n",
    "    df = pd.DataFrame(no_MGC_segment)\n",
    "    df = trim_columns_after_first_number(df)\n",
    "    newdf = replace_sweden_with_swed(df)\n",
    "    second = drop_matching_columns_without_prefix(newdf)\n",
    "    return second \n",
    "\n",
    "def combine_columns(df):\n",
    "    \"\"\"\n",
    "    Combine columns with the same name.\n",
    "    After combining, if any of the columns has a 1, set the row value to 1, otherwise 0.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame to modify.\n",
    "\n",
    "    Returns:\n",
    "    - Modified DataFrame with combined columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get unique column names\n",
    "    unique_cols = df.columns.unique()\n",
    "\n",
    "    for col in unique_cols:\n",
    "        # If there are multiple columns with the same name\n",
    "        if sum(df.columns == col) > 1:\n",
    "            # Combine columns and check if any of them has a 1\n",
    "            df[col] = df[col].max(axis=1).astype(int)\n",
    "\n",
    "            # Drop duplicate columns, keeping only the first occurrence\n",
    "            df = df.loc[:, ~df.columns.duplicated(keep='first')]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eIQcOtt2ZsVg"
   },
   "outputs": [],
   "source": [
    "cleaned_abs_pres= clean_the_names(abspres)\n",
    "cleaned_relInt= clean_the_names(files_toclean)\n",
    "DetectedinAll = cleaned_abs_pres.multiply(cleaned_relInt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Austria_01</th>\n",
       "      <th>Austria_02</th>\n",
       "      <th>Austria_03</th>\n",
       "      <th>Austria_04</th>\n",
       "      <th>Austria_05</th>\n",
       "      <th>Austria_06</th>\n",
       "      <th>Austria_07</th>\n",
       "      <th>Croatia_01</th>\n",
       "      <th>Croatia_02</th>\n",
       "      <th>Croatia_03</th>\n",
       "      <th>...</th>\n",
       "      <th>Italy_06</th>\n",
       "      <th>MasterMix_</th>\n",
       "      <th>Norway_07</th>\n",
       "      <th>Norway_14</th>\n",
       "      <th>Swed_04</th>\n",
       "      <th>Swed_16</th>\n",
       "      <th>Swed_25</th>\n",
       "      <th>Swed_302</th>\n",
       "      <th>Swed_35</th>\n",
       "      <th>Swed_45</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calibrated m/z</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100.040385</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101.024427</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.741678e+06</td>\n",
       "      <td>2.785370e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.520501e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101.060776</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103.022346</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103.040016</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999.922333</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999.926835</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999.928320</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999.939351</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999.953160</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219397 rows Ã— 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Austria_01    Austria_02    Austria_03  Austria_04  \\\n",
       "Calibrated m/z                                                       \n",
       "100.040385             0.0  0.000000e+00  0.000000e+00         0.0   \n",
       "101.024427             0.0  6.741678e+06  2.785370e+06         0.0   \n",
       "101.060776             0.0  0.000000e+00  0.000000e+00         0.0   \n",
       "103.022346             0.0  0.000000e+00  0.000000e+00         0.0   \n",
       "103.040016             0.0  0.000000e+00  0.000000e+00         0.0   \n",
       "...                    ...           ...           ...         ...   \n",
       "999.922333             0.0  0.000000e+00  0.000000e+00         0.0   \n",
       "999.926835             0.0  0.000000e+00  0.000000e+00         0.0   \n",
       "999.928320             0.0  0.000000e+00  0.000000e+00         0.0   \n",
       "999.939351             0.0  0.000000e+00  0.000000e+00         0.0   \n",
       "999.953160             0.0  0.000000e+00  0.000000e+00         0.0   \n",
       "\n",
       "                Austria_05  Austria_06  Austria_07  Croatia_01    Croatia_02  \\\n",
       "Calibrated m/z                                                                 \n",
       "100.040385             0.0         0.0         0.0         0.0  0.000000e+00   \n",
       "101.024427             0.0         0.0         0.0         0.0  8.520501e+06   \n",
       "101.060776             0.0         0.0         0.0         0.0  0.000000e+00   \n",
       "103.022346             0.0         0.0         0.0         0.0  0.000000e+00   \n",
       "103.040016             0.0         0.0         0.0         0.0  0.000000e+00   \n",
       "...                    ...         ...         ...         ...           ...   \n",
       "999.922333             0.0         0.0         0.0         0.0  0.000000e+00   \n",
       "999.926835             0.0         0.0         0.0         0.0  0.000000e+00   \n",
       "999.928320             0.0         0.0         0.0         0.0  0.000000e+00   \n",
       "999.939351             0.0         0.0         0.0         0.0  0.000000e+00   \n",
       "999.953160             0.0         0.0         0.0         0.0  0.000000e+00   \n",
       "\n",
       "                Croatia_03  ...  Italy_06  MasterMix_  Norway_07  Norway_14  \\\n",
       "Calibrated m/z              ...                                               \n",
       "100.040385             0.0  ...       0.0         0.0        0.0        0.0   \n",
       "101.024427             0.0  ...       0.0         0.0        0.0        0.0   \n",
       "101.060776             0.0  ...       0.0         0.0        0.0        0.0   \n",
       "103.022346             0.0  ...       0.0         0.0        0.0        0.0   \n",
       "103.040016             0.0  ...       0.0         0.0        0.0        0.0   \n",
       "...                    ...  ...       ...         ...        ...        ...   \n",
       "999.922333             0.0  ...       0.0         0.0        0.0        0.0   \n",
       "999.926835             0.0  ...       0.0         0.0        0.0        0.0   \n",
       "999.928320             0.0  ...       0.0         0.0        0.0        0.0   \n",
       "999.939351             0.0  ...       0.0         0.0        0.0        0.0   \n",
       "999.953160             0.0  ...       0.0         0.0        0.0        0.0   \n",
       "\n",
       "                Swed_04  Swed_16  Swed_25  Swed_302  Swed_35  Swed_45  \n",
       "Calibrated m/z                                                         \n",
       "100.040385          0.0      0.0      0.0       0.0      0.0      0.0  \n",
       "101.024427          0.0      0.0      0.0       0.0      0.0      0.0  \n",
       "101.060776          0.0      0.0      0.0       0.0      0.0      0.0  \n",
       "103.022346          0.0      0.0      0.0       0.0      0.0      0.0  \n",
       "103.040016          0.0      0.0      0.0       0.0      0.0      0.0  \n",
       "...                 ...      ...      ...       ...      ...      ...  \n",
       "999.922333          0.0      0.0      0.0       0.0      0.0      0.0  \n",
       "999.926835          0.0      0.0      0.0       0.0      0.0      0.0  \n",
       "999.928320          0.0      0.0      0.0       0.0      0.0      0.0  \n",
       "999.939351          0.0      0.0      0.0       0.0      0.0      0.0  \n",
       "999.953160          0.0      0.0      0.0       0.0      0.0      0.0  \n",
       "\n",
       "[219397 rows x 121 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = DetectedinAll.groupby(by=DetectedinAll.columns, axis=1).mean()\n",
    "cleaned_result = combine_columns(result)\n",
    "df_cleaned = remove_retain_prefix(cleaned_result)\n",
    "display(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rqCpL2tg-8hk"
   },
   "outputs": [],
   "source": [
    "df= merge_and_export(files_toclean, df_cleaned, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
